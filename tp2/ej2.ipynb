{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be78b4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de NaNs en titleSentiment 26\n",
      "Cantidad de registros 257\n",
      "Cantidad de registros despues de sacar NaNs: 231.\n",
      "     starRating  wordcount  titleSentiment  sentimentValue\n",
      "0             1         20             0.0       -0.486389\n",
      "1             1          6             0.0       -0.586187\n",
      "4             1          6             0.0       -0.651784\n",
      "5             1          8             1.0       -0.720443\n",
      "6             1         11             1.0       -0.726825\n",
      "7             1         16             1.0       -0.736769\n",
      "8             1          3             1.0       -0.765284\n",
      "9             1         13             0.0       -0.797961\n",
      "10            1          4             1.0       -0.833488\n",
      "11            1          9             0.0       -0.838467\n",
      "12            1          2             1.0       -0.888559\n",
      "13            1         23             0.0       -1.002696\n",
      "14            1          7             0.0       -1.083269\n",
      "15            1         10             1.0       -1.098110\n",
      "16            1          1             0.0       -1.104469\n",
      "17            1          7             1.0       -1.112223\n",
      "18            1          5             1.0       -1.275411\n",
      "19            1          5             1.0       -1.286009\n",
      "20            1          3             1.0       -1.455640\n",
      "21            1          7             0.0       -1.479433\n",
      "22            1         10             0.0       -1.498306\n",
      "23            1          3             1.0       -1.780889\n",
      "24            1          2             1.0       -2.276469\n",
      "25            1         29             1.0        0.107671\n",
      "26            2         15             0.0       -0.062616\n",
      "27            2         11             1.0       -0.063282\n",
      "28            2         28             0.0       -0.130138\n",
      "29            2          8             1.0       -0.201710\n",
      "31            2          3             0.0       -0.552986\n",
      "32            2         15             0.0       -0.615022\n",
      "33            2          6             0.0       -0.642228\n",
      "34            2          7             1.0       -0.747805\n",
      "35            2         27             1.0       -0.769309\n",
      "36            2         17             0.0       -0.950121\n",
      "37            2          8             0.0       -1.707268\n",
      "38            2          1             0.0        0.052841\n",
      "39            2         20             1.0        0.057928\n",
      "40            2          8             1.0        0.073779\n",
      "42            3          7             1.0       -0.015019\n",
      "43            3          4             1.0       -0.022035\n",
      "44            3          2             1.0       -0.036155\n",
      "45            3          6             1.0       -0.048439\n",
      "46            3         14             1.0       -0.061755\n",
      "47            3          3             1.0       -0.065483\n",
      "48            3          6             1.0       -0.070441\n",
      "49            3          2             1.0       -0.074483\n",
      "50            3          1             1.0       -0.083467\n",
      "51            3          1             1.0       -0.083467\n",
      "52            3          2             1.0       -0.088824\n",
      "53            3          2             1.0       -0.089639\n",
      "54            3          4             1.0       -0.092401\n",
      "55            3          2             1.0       -0.096387\n",
      "56            3          9             1.0       -0.100422\n",
      "57            3          3             1.0       -0.106498\n",
      "58            3          7             1.0       -0.107456\n",
      "59            3          3             1.0       -0.107755\n",
      "60            3          5             1.0       -0.108144\n",
      "62            3          4             1.0       -0.114317\n",
      "63            3          1             1.0       -0.116132\n",
      "64            3          5             0.0       -0.137943\n",
      "65            3          1             1.0       -0.139861\n",
      "66            3          1             1.0       -0.139861\n",
      "69            3          1             1.0       -0.171701\n",
      "70            3          1             1.0       -0.213092\n",
      "71            3          7             1.0       -0.227463\n",
      "72            3          2             1.0       -0.236295\n",
      "73            3          3             1.0       -0.246730\n",
      "74            1          3             1.0       -0.256026\n",
      "75            3          4             0.0       -0.256112\n",
      "76            3          9             1.0       -0.257639\n",
      "77            3          1             0.0       -0.300491\n",
      "78            1          3             1.0       -0.311820\n",
      "79            1          1             1.0       -0.348733\n",
      "80            1         11             0.0       -0.355790\n",
      "81            1          3             1.0       -0.365337\n",
      "82            1         14             0.0       -0.376121\n",
      "84            3         28             1.0       -0.406623\n",
      "85            1          5             0.0       -0.439639\n",
      "86            3          5             1.0       -0.446730\n",
      "87            1          3             1.0       -0.465646\n",
      "88            1          4             0.0       -0.466102\n",
      "89            1         17             0.0       -0.493784\n",
      "91            3          4             1.0        0.004820\n",
      "92            3          4             1.0        0.020340\n",
      "93            3         19             1.0        0.034394\n",
      "94            3          7             1.0        0.035112\n",
      "95            3          2             1.0        0.039896\n",
      "96            3          3             1.0        0.042369\n",
      "97            3          5             1.0        0.048475\n",
      "98            3          5             1.0        0.066694\n",
      "99            3          6             1.0        0.078157\n",
      "100           3          2             1.0        0.081264\n",
      "101           3          3             1.0        0.104674\n",
      "103           3         12             1.0        0.132087\n",
      "104           3          2             1.0        0.136207\n",
      "106           3          1             1.0        0.151900\n",
      "107           3          1             1.0        0.153141\n",
      "108           3          3             1.0        0.157436\n",
      "109           3          6             1.0        0.160616\n",
      "110           3          4             1.0        0.170651\n",
      "111           3          2             1.0        0.190015\n",
      "112           3          3             1.0        0.201199\n",
      "113           3          5             1.0        0.212674\n",
      "114           3          3             1.0        0.218230\n",
      "115           3          4             1.0        0.237717\n",
      "116           3          1             1.0        0.238396\n",
      "117           3         11             1.0        0.244713\n",
      "118           3          6             1.0        0.246869\n",
      "119           3          3             1.0        0.281624\n",
      "120           3          3             1.0        0.283673\n",
      "121           3          1             1.0        0.288224\n",
      "122           3          5             1.0        0.297272\n",
      "125           3          5             0.0        0.301521\n",
      "126           3          4             1.0        0.308424\n",
      "127           3          2             1.0        0.310468\n",
      "128           3          2             1.0        2.066294\n",
      "129           3          1             1.0        2.494902\n",
      "130           4          7             1.0        0.107111\n",
      "131           2         17             1.0        0.136766\n",
      "132           2          5             1.0        0.145602\n",
      "133           2         26             1.0        0.157160\n",
      "134           2          5             0.0        0.193291\n",
      "136           2          6             1.0        0.214543\n",
      "137           2         26             1.0        0.226819\n",
      "138           4          7             0.0        0.236713\n",
      "139           2         17             1.0        0.264091\n",
      "141           4          4             1.0        0.315914\n",
      "142           2          9             0.0        0.319576\n",
      "143           2         12             1.0        0.358095\n",
      "144           4          6             1.0        0.397294\n",
      "145           4          6             1.0        0.400986\n",
      "146           4          6             1.0        0.472362\n",
      "147           4         10             1.0        0.511459\n",
      "148           4          3             1.0        0.513035\n",
      "149           4          5             1.0        0.528874\n",
      "150           4          5             1.0        0.581934\n",
      "151           4         12             0.0        0.743365\n",
      "152           4         13             1.0        0.808384\n",
      "153           4          5             1.0        0.813521\n",
      "154           4          9             1.0        0.870911\n",
      "155           4         14             1.0        0.911598\n",
      "156           4         10             1.0        2.078533\n",
      "157           5          3             1.0        0.319412\n",
      "158           5          1             1.0        0.335548\n",
      "159           5          6             1.0        0.340636\n",
      "160           5          1             1.0        0.340838\n",
      "161           5          7             1.0        0.344929\n",
      "162           5          1             1.0        0.373013\n",
      "163           5          4             1.0        0.377286\n",
      "164           5          1             1.0        0.410584\n",
      "165           4          7             1.0        0.416996\n",
      "166           5          8             1.0        0.436012\n",
      "167           4          6             1.0        0.458070\n",
      "168           5          6             1.0        0.462592\n",
      "169           5          7             0.0        0.475378\n",
      "170           4         12             1.0        0.502011\n",
      "171           5          2             1.0        0.531343\n",
      "172           5          2             1.0        0.556533\n",
      "173           4          2             1.0        0.590758\n",
      "174           5          5             1.0        0.598366\n",
      "175           4         12             1.0        0.626541\n",
      "177           5          6             1.0        0.644797\n",
      "178           5          3             1.0        0.647472\n",
      "179           5          2             1.0        0.650792\n",
      "180           5          5             1.0        0.651691\n",
      "181           5          9             1.0        0.660120\n",
      "182           4          2             1.0        0.664222\n",
      "183           5          5             1.0        0.666522\n",
      "184           5          3             1.0        0.670468\n",
      "185           5          3             1.0        0.680167\n",
      "186           5          6             1.0        0.681880\n",
      "187           5          3             0.0        0.681937\n",
      "188           5         10             0.0        0.693039\n",
      "189           5          4             1.0        0.694613\n",
      "190           5          3             1.0        0.703685\n",
      "192           5          2             1.0        0.729001\n",
      "193           5          2             1.0        0.736485\n",
      "194           5          6             1.0        0.777594\n",
      "195           5          2             1.0        0.789284\n",
      "196           5          2             1.0        0.789284\n",
      "197           5          9             1.0        0.794211\n",
      "198           5          9             1.0        0.796459\n",
      "199           5          6             1.0        0.825006\n",
      "200           5          5             1.0        0.848620\n",
      "202           5          3             1.0        0.950245\n",
      "204           4         11             1.0        0.970350\n",
      "207           4         10             1.0        0.987533\n",
      "208           5          4             1.0        1.015807\n",
      "209           5          8             1.0        1.034916\n",
      "210           5          6             1.0        1.080510\n",
      "211           5          5             1.0        1.112476\n",
      "212           4         11             1.0        1.117629\n",
      "213           5          4             1.0        1.132486\n",
      "214           5          1             1.0        1.165488\n",
      "215           5          1             1.0        1.165488\n",
      "216           5          7             1.0        1.173869\n",
      "217           5          3             1.0        1.175564\n",
      "218           5          2             1.0        1.204502\n",
      "219           5          5             1.0        1.213158\n",
      "220           5          1             1.0        1.213942\n",
      "221           4         14             1.0        1.252075\n",
      "222           5          2             1.0        1.271260\n",
      "223           5          3             1.0        1.294011\n",
      "224           5          4             1.0        1.362262\n",
      "225           5          2             1.0        1.379530\n",
      "226           5          2             1.0        1.379530\n",
      "228           5          3             0.0        1.405697\n",
      "229           5          9             1.0        1.413723\n",
      "230           5          2             1.0        1.422714\n",
      "231           5          7             1.0        1.425077\n",
      "232           5          5             1.0        1.496927\n",
      "234           5          2             1.0        1.593301\n",
      "236           5          3             1.0        1.630900\n",
      "237           4          5             1.0        1.769818\n",
      "238           5          1             1.0        1.837082\n",
      "239           5          5             1.0        1.881806\n",
      "240           5          3             1.0        1.943862\n",
      "241           5          3             1.0        1.943862\n",
      "242           5          2             1.0        2.052932\n",
      "243           5          7             1.0        2.055556\n",
      "244           5          2             1.0        2.066294\n",
      "245           5          2             1.0        2.066294\n",
      "247           5          5             1.0        2.098547\n",
      "248           5          1             1.0        2.220387\n",
      "249           5          2             1.0        2.295086\n",
      "251           5          1             1.0        2.494902\n",
      "252           5          3             1.0        2.814818\n",
      "253           5          1             1.0        2.924393\n",
      "254           5          1             1.0        2.924393\n",
      "255           5          1             1.0        2.924393\n",
      "256           5          3             0.0        3.264579\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.knn import KNN, WeightedKNN\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "\n",
    "attributes = ['wordcount', 'titleSentiment', 'sentimentValue']\n",
    "target = ['starRating']\n",
    "\n",
    "reviews_sentiment = pd.read_csv('datasets/reviews_sentiment.csv', delimiter=\";\")\n",
    "\n",
    "for i, row in reviews_sentiment.iterrows():\n",
    "    wc = len(row['reviewText'].strip().split(' '))\n",
    "    if wc != row['wordcount']:\n",
    "#         print(f\"El registro {i} tiene el campo wordcount incorrecto, corrigiendo...\")\n",
    "        reviews_sentiment.at[i,'wordcount'] = wc\n",
    "\n",
    "# print(sentiments)\n",
    "\n",
    "# cambiar positivo a 1, negativo a 0.\n",
    "reviews_sentiment['titleSentiment'].replace('positive', 1, inplace=True)\n",
    "reviews_sentiment['titleSentiment'].replace('negative', 0, inplace=True)\n",
    "\n",
    "# quitar los NaNs y verificar que no sea una porcion importante del conjunto de datos\n",
    "nan_title_sentiment = reviews_sentiment[reviews_sentiment['titleSentiment'].isna()]\n",
    "nan_text_sentiment = reviews_sentiment[reviews_sentiment['textSentiment'].isna()]\n",
    "print(f\"Cantidad de NaNs en titleSentiment {len(nan_title_sentiment)}\")\n",
    "print(f\"Cantidad de registros {len(reviews_sentiment)}\")\n",
    "reviews_sentiment = reviews_sentiment.dropna()\n",
    "print(f\"Cantidad de registros despues de sacar NaNs: {len(reviews_sentiment)}.\")\n",
    "\n",
    "reviews_sentiment = reviews_sentiment[target + attributes]\n",
    "\n",
    "print(reviews_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8697cbcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los comentarios valorados con 1 estrella, ¿que cantidad promedio de palabras tienen?\n",
      "El promedio es 8.06\n"
     ]
    }
   ],
   "source": [
    "# Pregunta a)\n",
    "print('Los comentarios valorados con 1 estrella, ¿que cantidad promedio de palabras tienen?')\n",
    "\n",
    "mean = reviews_sentiment[reviews_sentiment['starRating'] == 1]['wordcount'].aggregate('mean')\n",
    "print(f\"El promedio es {round(mean, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f16adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.aux_functions import normalize_df\n",
    "\n",
    "classes = np.array(reviews_sentiment.starRating.unique())\n",
    "\n",
    "# print(sentiments.star_rating.unique())\n",
    "\n",
    "labels = np.array(reviews_sentiment.starRating)\n",
    "# Se normalizan los datos por cada columna\n",
    "data = np.array(normalize_df(reviews_sentiment[attributes])) # me queda un arreglo de registros con 3 atributos\n",
    "\n",
    "crossed_validation = 6\n",
    "batch_size = math.floor(len(data)/crossed_validation)\n",
    "\n",
    "# valores de precision para cada corrido de validacion cruzada\n",
    "knn_precisions = np.zeros(crossed_validation)\n",
    "weight_knn_precisions = np.zeros(crossed_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fcbc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n",
      "step_k\n"
     ]
    }
   ],
   "source": [
    "from src.aux_functions import confusion_matrix\n",
    "from src.aux_functions import plot_matrix\n",
    "from src.aux_functions import plot_precision\n",
    "\n",
    "\n",
    "for i in range(crossed_validation):\n",
    "\n",
    "    # separo por lotes al conjunto de entrenamiento/testeo para la validacion cruzada\n",
    "    test_batch = np.array(range(batch_size * i, batch_size * (i + 1), 1))\n",
    "\n",
    "    # b) Dividir el conjunto de datos en un conjunto de entrenamiento y otro de prueba.\n",
    "    X = np.delete(data, test_batch, axis = 0)\n",
    "    f_X = np.delete(labels, test_batch, axis = 0)\n",
    "    Y = data[test_batch[0]:(test_batch[-1] + 1)]\n",
    "    f_Y = labels[test_batch[0]:(test_batch[-1] + 1)]\n",
    "\n",
    "    knn = KNN(X, f_X, classes)\n",
    "    weight_knn = WeightedKNN(X, f_X, classes)\n",
    "\n",
    "    predictions = knn.batch_classify(Y)\n",
    "    weight_predictions = weight_knn.batch_classify(Y)\n",
    "    \n",
    "#     knn_confusion = confusion_matrix(results, f_Y, classes)\n",
    "    weight_knn_confusion = confusion_matrix(weight_predictions, f_Y, classes)\n",
    "\n",
    "#     knn_precisions[i] = knn_confusion.trace()/knn_confusion.sum()\n",
    "    weight_knn_precisions[i] = weight_knn_confusion.trace()/weight_knn_confusion.sum()\n",
    "#     plot_matrix(weight_knn_confusion, f'crossed_validation_{crossed_validation}_{i}.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8014c395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "plot_precision(knn_precisions, weight_knn_precisions, crossed_validation, f'crossed_validation_{crossed_validation}.png')\n",
    "\n",
    "print()\n",
    "# print(f'Para el KNN pesado, la precision promedio resulto: {w_knn_precisions.mean()} con un valor maximo de: {w_knn_precisions.max()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
