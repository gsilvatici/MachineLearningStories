{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be78b4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7587548638132295\n",
      "Cantidad de NaNs en titleSentiment 0\n",
      "Cantidad de registros 257\n",
      "Cantidad de registros despues de sacar NaNs: 257.\n",
      "     starRating  wordcount  titleSentiment  sentimentValue\n",
      "0             5          3        1.000000        1.943862\n",
      "1             5          2        1.000000        0.556533\n",
      "2             3          6        1.000000        0.160616\n",
      "3             4          6        1.000000        0.400986\n",
      "4             5          4        1.000000        1.362262\n",
      "5             5          9        1.000000        0.796459\n",
      "6             2          1        0.000000        0.052841\n",
      "7             1          3        1.000000       -0.256026\n",
      "8             5          6        1.000000        1.080510\n",
      "9             1          8        1.000000       -0.720443\n",
      "10            5          2        1.000000        0.729001\n",
      "11            3          5        0.000000       -0.137943\n",
      "12            3          7        1.000000       -0.227463\n",
      "13            1          7        1.000000       -1.112223\n",
      "14            5          5        1.000000        1.112476\n",
      "15            1         10        0.000000       -1.498306\n",
      "16            5          7        1.000000        1.425077\n",
      "17            3          2        1.000000        0.136207\n",
      "18            3          1        1.000000        2.494902\n",
      "19            1          3        1.000000       -1.780889\n",
      "20            3          1        1.000000       -0.139861\n",
      "21            1          2        1.000000       -0.888559\n",
      "22            2         15        0.000000       -0.062616\n",
      "23            3          5        1.000000       -0.108144\n",
      "24            2          5        1.000000        0.145602\n",
      "25            4          7        1.000000        0.416996\n",
      "26            5          1        1.000000        2.924393\n",
      "27            5          2        1.000000        1.271260\n",
      "28            4          5        1.000000        0.528874\n",
      "29            5          2        1.000000        1.379530\n",
      "30            3          1        0.758755       -0.139861\n",
      "31            2         17        1.000000        0.264091\n",
      "32            3          5        1.000000        0.297272\n",
      "33            3          2        1.000000        2.066294\n",
      "34            3         19        1.000000        0.034394\n",
      "35            1          6        0.000000       -0.651784\n",
      "36            5          3        1.000000        1.294011\n",
      "37            5          3        1.000000        1.175564\n",
      "38            3          3        1.000000        0.218230\n",
      "39            1          9        0.000000       -0.838467\n",
      "40            5          2        1.000000        0.789284\n",
      "41            3          7        1.000000       -0.015019\n",
      "42            4          7        1.000000        0.107111\n",
      "43            5          8        1.000000        1.034916\n",
      "44            4          3        0.758755        0.272991\n",
      "45            3          3        1.000000        0.042369\n",
      "46            5          9        0.758755        1.527797\n",
      "47            2         26        1.000000        0.157160\n",
      "48            1         13        0.000000       -0.797961\n",
      "49            3          1        1.000000        0.153141\n",
      "50            1          4        0.758755       -0.602240\n",
      "51            3          6        1.000000        0.246869\n",
      "52            3          2        1.000000        0.310468\n",
      "53            3          4        1.000000       -0.114317\n",
      "54            5          5        1.000000        1.496927\n",
      "55            5          3        1.000000        0.670468\n",
      "56            3          6        1.000000       -0.070441\n",
      "57            5          3        0.000000        0.681937\n",
      "58            5          3        1.000000        0.647472\n",
      "59            3          1        0.000000       -0.300491\n",
      "60            5          2        1.000000        2.066294\n",
      "61            3          1        0.758755        0.297443\n",
      "62            5          2        0.758755        1.593301\n",
      "63            1          7        0.000000       -1.083269\n",
      "64            3          3        1.000000       -0.107755\n",
      "65            5          2        1.000000        1.379530\n",
      "66            4          5        1.000000        0.813521\n",
      "67            1          3        1.000000       -0.365337\n",
      "68            5          1        1.000000        1.837082\n",
      "69            5          9        1.000000        0.660120\n",
      "70            1         20        0.000000       -0.486389\n",
      "71            3          4        1.000000       -0.022035\n",
      "72            5          7        1.000000        0.344929\n",
      "73            3         12        1.000000        0.132087\n",
      "74            5          5        1.000000        0.651691\n",
      "75            1         23        0.000000       -1.002696\n",
      "76            1         17        0.000000       -0.493784\n",
      "77            5          2        1.000000        1.422714\n",
      "78            3          1        1.000000       -0.116132\n",
      "79            5          9        1.000000        0.794211\n",
      "80            3          4        1.000000        0.004820\n",
      "81            3          4        1.000000       -0.092401\n",
      "82            3          5        1.000000        0.066694\n",
      "83            2         17        0.000000       -0.950121\n",
      "84            5          6        1.000000        0.462592\n",
      "85            3          2        0.758755       -0.012039\n",
      "86            5          6        1.000000        0.644797\n",
      "87            3          5        1.000000        0.048475\n",
      "88            5          7        0.000000        0.475378\n",
      "89            3          7        1.000000        0.035112\n",
      "90            3          2        0.758755        0.125126\n",
      "91            3          2        1.000000       -0.074483\n",
      "92            5          2        1.000000        0.736485\n",
      "93            5          1        1.000000        0.340838\n",
      "94            5          5        1.000000        2.098547\n",
      "95            5          6        1.000000        0.340636\n",
      "96            3          2        1.000000       -0.088824\n",
      "97            5         10        0.000000        0.693039\n",
      "98            4         10        1.000000        0.511459\n",
      "99            4          7        0.000000        0.236713\n",
      "100           5          1        1.000000        1.213942\n",
      "101           5          5        1.000000        1.213158\n",
      "102           5          1        1.000000        1.165488\n",
      "103           5          1        1.000000        2.220387\n",
      "104           5          2        1.000000        0.650792\n",
      "105           1         11        1.000000       -0.726825\n",
      "106           1          3        1.000000       -0.465646\n",
      "107           1         14        0.000000       -0.376121\n",
      "108           5          2        1.000000        0.789284\n",
      "109           4          5        1.000000        0.581934\n",
      "110           5          4        1.000000        1.132486\n",
      "111           4         14        1.000000        0.911598\n",
      "112           5          5        1.000000        0.598366\n",
      "113           1         17        0.758755       -0.616271\n",
      "114           5          3        1.000000        2.814818\n",
      "115           5          4        1.000000        1.015807\n",
      "116           2          3        0.758755       -0.295194\n",
      "117           3          6        1.000000        0.078157\n",
      "118           3          3        1.000000        0.157436\n",
      "119           5          6        0.758755        0.983344\n",
      "120           1         16        1.000000       -0.736769\n",
      "121           1          7        0.000000       -1.479433\n",
      "122           3          3        0.758755        0.297791\n",
      "123           5          6        1.000000        0.777594\n",
      "124           3          9        1.000000       -0.100422\n",
      "125           4         10        1.000000        2.078533\n",
      "126           2         28        0.000000       -0.130138\n",
      "127           5          3        1.000000        1.943862\n",
      "128           3          1        1.000000       -0.213092\n",
      "129           4         12        0.000000        0.743365\n",
      "130           5          1        1.000000        2.924393\n",
      "131           3          7        1.000000       -0.107456\n",
      "132           3          3        1.000000       -0.065483\n",
      "133           5          9        1.000000        1.413723\n",
      "134           3          2        1.000000       -0.096387\n",
      "135           5          3        0.000000        1.405697\n",
      "136           3          4        0.758755        0.136882\n",
      "137           5          2        0.758755        2.333013\n",
      "138           4         11        1.000000        1.117629\n",
      "139           5          3        1.000000        0.680167\n",
      "140           2          3        0.000000       -0.552986\n",
      "141           2         20        1.000000        0.057928\n",
      "142           5          2        1.000000        1.593301\n",
      "143           4          6        1.000000        0.458070\n",
      "144           5          1        1.000000        2.924393\n",
      "145           5          2        1.000000        1.204502\n",
      "146           5          1        0.758755        0.727406\n",
      "147           3          2        1.000000        0.081264\n",
      "148           2          8        1.000000        0.073779\n",
      "149           5          1        1.000000        0.373013\n",
      "150           5          3        1.000000        0.950245\n",
      "151           5          1        1.000000        1.165488\n",
      "152           5          6        1.000000        0.825006\n",
      "153           3          6        1.000000       -0.048439\n",
      "154           5          1        1.000000        2.494902\n",
      "155           3          1        1.000000       -0.083467\n",
      "156           2          6        1.000000        0.214543\n",
      "157           4          8        0.758755        0.876946\n",
      "158           2          9        0.000000        0.319576\n",
      "159           4          2        1.000000        0.590758\n",
      "160           4         14        1.000000        1.252075\n",
      "161           1         11        0.000000       -0.355790\n",
      "162           4         10        1.000000        0.987533\n",
      "163           3         14        1.000000       -0.061755\n",
      "164           3          2        1.000000       -0.089639\n",
      "165           5          4        1.000000        0.377286\n",
      "166           5          3        0.000000        3.264579\n",
      "167           5          5        1.000000        1.881806\n",
      "168           5          4        1.000000        0.694613\n",
      "169           5          7        1.000000        2.055556\n",
      "170           2          6        0.000000       -0.642228\n",
      "171           2         15        0.000000       -0.615022\n",
      "172           3          2        1.000000       -0.236295\n",
      "173           1          5        1.000000       -1.286009\n",
      "174           1          3        1.000000       -1.455640\n",
      "175           5          2        1.000000        2.052932\n",
      "176           3          1        0.758755       -0.139861\n",
      "177           4          5        1.000000        1.769818\n",
      "178           5          6        1.000000        0.681880\n",
      "179           3          9        1.000000       -0.257639\n",
      "180           1         29        1.000000        0.107671\n",
      "181           3         28        1.000000       -0.406623\n",
      "182           3          1        1.000000        0.238396\n",
      "183           5          3        1.000000        0.319412\n",
      "184           2          8        1.000000       -0.201710\n",
      "185           5          2        0.758755        2.066294\n",
      "186           3          5        0.758755       -0.110967\n",
      "187           2         12        1.000000        0.358095\n",
      "188           3          2        1.000000        0.039896\n",
      "189           4          6        1.000000        0.397294\n",
      "190           4         12        1.000000        0.502011\n",
      "191           3         11        1.000000        0.244713\n",
      "192           3          4        1.000000        0.020340\n",
      "193           4          2        1.000000        0.664222\n",
      "194           5          4        0.758755        0.634096\n",
      "195           5          3        1.000000        1.630900\n",
      "196           2         26        1.000000        0.226819\n",
      "197           2          8        0.000000       -1.707268\n",
      "198           4          5        0.758755        0.199283\n",
      "199           3          5        1.000000       -0.446730\n",
      "200           4          4        1.000000        0.315914\n",
      "201           3          8        0.758755        0.001546\n",
      "202           5          2        1.000000        2.295086\n",
      "203           5          1        1.000000        0.410584\n",
      "204           3          5        0.000000        0.301521\n",
      "205           1          2        1.000000       -2.276469\n",
      "206           5          2        1.000000        2.066294\n",
      "207           2         11        1.000000       -0.063282\n",
      "208           1          4        1.000000       -0.833488\n",
      "209           3          3        1.000000        0.201199\n",
      "210           5          6        0.758755        1.395646\n",
      "211           5          1        1.000000        0.335548\n",
      "212           1          7        0.758755       -0.396850\n",
      "213           4         13        1.000000        0.808384\n",
      "214           4         12        1.000000        0.626541\n",
      "215           3          3        1.000000        0.283673\n",
      "216           5          3        1.000000        0.703685\n",
      "217           2          7        1.000000       -0.747805\n",
      "218           3          3        1.000000        0.104674\n",
      "219           3          1        1.000000       -0.171701\n",
      "220           1          3        1.000000       -0.311820\n",
      "221           3          2        1.000000        0.190015\n",
      "222           3          1        1.000000        0.151900\n",
      "223           3          3        1.000000       -0.246730\n",
      "224           5          8        1.000000        0.436012\n",
      "225           4          6        1.000000        0.472362\n",
      "226           1          1        1.000000       -0.348733\n",
      "227           4         11        1.000000        0.970350\n",
      "228           2          5        0.000000        0.193291\n",
      "229           3          1        1.000000       -0.083467\n",
      "230           5          3        0.758755        0.950245\n",
      "231           3          1        1.000000        0.288224\n",
      "232           2         27        1.000000       -0.769309\n",
      "233           1          3        1.000000       -0.765284\n",
      "234           3          4        0.000000       -0.256112\n",
      "235           5          3        0.758755        0.984504\n",
      "236           1          5        1.000000       -1.275411\n",
      "237           5          5        1.000000        0.848620\n",
      "238           3          4        1.000000        0.308424\n",
      "239           1          5        0.000000       -0.439639\n",
      "240           3          4        1.000000        0.170651\n",
      "241           1          4        0.000000       -0.466102\n",
      "242           3          3        1.000000       -0.106498\n",
      "243           5          5        1.000000        0.666522\n",
      "244           2         17        1.000000        0.136766\n",
      "245           1          6        0.000000       -0.586187\n",
      "246           3          1        1.000000       -0.139861\n",
      "247           4          3        1.000000        0.513035\n",
      "248           3          2        1.000000       -0.036155\n",
      "249           3          5        1.000000        0.212674\n",
      "250           3          3        1.000000        0.281624\n",
      "251           3          4        1.000000        0.237717\n",
      "252           4          9        1.000000        0.870911\n",
      "253           1         10        1.000000       -1.098110\n",
      "254           1          1        0.000000       -1.104469\n",
      "255           5          2        1.000000        0.531343\n",
      "256           5          7        1.000000        1.173869\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.knn import KNN, WeightedKNN\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "\n",
    "reviews_sentiment = pd.read_csv('datasets/reviews_sentiment.csv', delimiter=\";\")\n",
    "\n",
    "for i, row in reviews_sentiment.iterrows():\n",
    "    wc = len(row['reviewText'].strip().split(' '))\n",
    "    if wc != row['wordcount']:\n",
    "#         print(f\"El registro {i} tiene el campo wordcount incorrecto, corrigiendo...\")\n",
    "        reviews_sentiment.at[i,'wordcount'] = wc\n",
    "\n",
    "# print(sentiments)\n",
    "\n",
    "# cambiar positivo a 1, negativo a 0.\n",
    "reviews_sentiment['titleSentiment'].replace('positive', 1, inplace=True)\n",
    "reviews_sentiment['titleSentiment'].replace('negative', 0, inplace=True)\n",
    "\n",
    "ones = reviews_sentiment[reviews_sentiment['titleSentiment'] == 1]['titleSentiment'].aggregate('sum')\n",
    "ceroes = reviews_sentiment[reviews_sentiment['titleSentiment'] == 0]['titleSentiment'].aggregate('sum')\n",
    "\n",
    "prop = ones/len(reviews_sentiment)\n",
    "print(prop) \n",
    "\n",
    "reviews_sentiment['titleSentiment'].fillna(prop, inplace=True)\n",
    "\n",
    "attributes = ['wordcount', 'titleSentiment', 'sentimentValue']\n",
    "target = ['starRating']\n",
    "\n",
    "# quitar los NaNs y verificar que no sea una porcion importante del conjunto de datos\n",
    "nan_title_sentiment = reviews_sentiment[reviews_sentiment['titleSentiment'].isna()]\n",
    "nan_text_sentiment = reviews_sentiment[reviews_sentiment['textSentiment'].isna()]\n",
    "print(f\"Cantidad de NaNs en titleSentiment {len(nan_title_sentiment)}\")\n",
    "print(f\"Cantidad de registros {len(reviews_sentiment)}\")\n",
    "reviews_sentiment = reviews_sentiment.dropna()\n",
    "print(f\"Cantidad de registros despues de sacar NaNs: {len(reviews_sentiment)}.\")\n",
    "\n",
    "reviews_sentiment = reviews_sentiment[target + attributes]\n",
    "reviews_sentiment = reviews_sentiment.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(reviews_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8697cbcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los comentarios valorados con 1 estrella, ¿que cantidad promedio de palabras tienen?\n",
      "El promedio es 8.16\n"
     ]
    }
   ],
   "source": [
    "# Pregunta a)\n",
    "print('Los comentarios valorados con 1 estrella, ¿que cantidad promedio de palabras tienen?')\n",
    "\n",
    "mean = reviews_sentiment[reviews_sentiment['starRating'] == 1]['wordcount'].aggregate('mean')\n",
    "print(f\"El promedio es {round(mean, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f16adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.aux_functions import normalize_df\n",
    "\n",
    "\n",
    "register_class = np.array(reviews_sentiment.starRating)\n",
    "classes = np.array(reviews_sentiment.starRating.unique())\n",
    "\n",
    "# print(sentiments.star_rating.unique())\n",
    "\n",
    "# Se normalizan los datos por cada columna\n",
    "norm_data = np.array(normalize_df(reviews_sentiment[attributes])) # me queda un arreglo de registros con 3 atributos\n",
    "crossed_validation = 10\n",
    "batch_size = math.floor(len(norm_data)/crossed_validation)\n",
    "\n",
    "# valores de precision para cada corrido de validacion cruzada\n",
    "knn_precisions = np.zeros(crossed_validation)\n",
    "weight_knn_precisions = np.zeros(crossed_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14011eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07142857 1.         0.76164866]\n",
      " [0.03571429 1.         0.51127554]\n",
      " [0.17857143 1.         0.43982391]\n",
      " [0.17857143 1.         0.48320381]\n",
      " [0.10714286 1.         0.65668655]\n",
      " [0.28571429 1.         0.55457533]\n",
      " [0.         0.         0.42037351]\n",
      " [0.07142857 1.         0.36463192]\n",
      " [0.17857143 1.         0.60583835]\n",
      " [0.25       1.         0.28081804]\n",
      " [0.03571429 1.         0.54240099]\n",
      " [0.14285714 0.         0.38594247]\n",
      " [0.21428571 1.         0.36978673]\n",
      " [0.21428571 1.         0.21011297]\n",
      " [0.14285714 1.         0.61160735]\n",
      " [0.32142857 0.         0.14043617]\n",
      " [0.21428571 1.         0.66802275]\n",
      " [0.03571429 1.         0.4354187 ]\n",
      " [0.         1.         0.86109546]\n",
      " [0.07142857 1.         0.08943796]\n",
      " [0.         1.         0.38559645]\n",
      " [0.03571429 1.         0.25047791]\n",
      " [0.5        0.         0.39953695]\n",
      " [0.14285714 1.         0.39132046]\n",
      " [0.14285714 1.         0.43711429]\n",
      " [0.21428571 1.         0.48609312]\n",
      " [0.         1.         0.93860629]\n",
      " [0.03571429 1.         0.64026332]\n",
      " [0.14285714 1.         0.50628389]\n",
      " [0.03571429 1.         0.65980284]\n",
      " [0.         0.75875486 0.38559645]\n",
      " [0.57142857 1.         0.45849814]\n",
      " [0.14285714 1.         0.46448636]\n",
      " [0.03571429 1.         0.78374399]\n",
      " [0.64285714 1.         0.41704448]\n",
      " [0.17857143 0.         0.29320907]\n",
      " [0.07142857 1.         0.64436918]\n",
      " [0.07142857 1.         0.62299291]\n",
      " [0.07142857 1.         0.45022153]\n",
      " [0.28571429 0.         0.25951816]\n",
      " [0.03571429 1.         0.55328042]\n",
      " [0.21428571 1.         0.40812684]\n",
      " [0.21428571 1.         0.43016772]\n",
      " [0.25       1.         0.59760999]\n",
      " [0.07142857 0.75875486 0.46010439]\n",
      " [0.07142857 1.         0.41848361]\n",
      " [0.28571429 0.75875486 0.68656076]\n",
      " [0.89285714 1.         0.43920018]\n",
      " [0.42857143 0.         0.26682821]\n",
      " [0.         1.         0.43847478]\n",
      " [0.10714286 0.75875486 0.30215022]\n",
      " [0.17857143 1.         0.45538999]\n",
      " [0.03571429 1.         0.4668678 ]\n",
      " [0.10714286 1.         0.39020633]\n",
      " [0.14285714 1.         0.68098966]\n",
      " [0.07142857 1.         0.53183754]\n",
      " [0.17857143 1.         0.39812479]\n",
      " [0.07142857 0.         0.53390732]\n",
      " [0.07142857 1.         0.52768737]\n",
      " [0.         0.         0.35660737]\n",
      " [0.03571429 1.         0.78374399]\n",
      " [0.         0.75875486 0.46451728]\n",
      " [0.03571429 0.75875486 0.69838235]\n",
      " [0.21428571 0.         0.2153383 ]\n",
      " [0.07142857 1.         0.39139057]\n",
      " [0.03571429 1.         0.65980284]\n",
      " [0.14285714 1.         0.55765454]\n",
      " [0.07142857 1.         0.34490454]\n",
      " [0.         1.         0.74237792]\n",
      " [0.28571429 1.         0.52997005]\n",
      " [0.67857143 0.         0.323058  ]\n",
      " [0.10714286 1.         0.40686069]\n",
      " [0.21428571 1.         0.47308702]\n",
      " [0.39285714 1.         0.43467523]\n",
      " [0.14285714 1.         0.52844889]\n",
      " [0.78571429 0.         0.22987943]\n",
      " [0.57142857 0.         0.3217234 ]\n",
      " [0.03571429 1.         0.66759637]\n",
      " [0.         1.         0.38987886]\n",
      " [0.28571429 1.         0.55416951]\n",
      " [0.10714286 1.         0.41170714]\n",
      " [0.10714286 1.         0.39416155]\n",
      " [0.14285714 1.         0.42287357]\n",
      " [0.57142857 0.         0.23936774]\n",
      " [0.17857143 1.         0.49432182]\n",
      " [0.03571429 0.75875486 0.40866454]\n",
      " [0.17857143 1.         0.52720462]\n",
      " [0.14285714 1.         0.4195857 ]\n",
      " [0.21428571 0.         0.49662931]\n",
      " [0.21428571 1.         0.41717407]\n",
      " [0.03571429 0.75875486 0.43341898]\n",
      " [0.03571429 1.         0.39739518]\n",
      " [0.03571429 1.         0.54375169]\n",
      " [0.         1.         0.47234868]\n",
      " [0.14285714 1.         0.78956472]\n",
      " [0.17857143 1.         0.47231225]\n",
      " [0.03571429 1.         0.39480703]\n",
      " [0.32142857 0.         0.53591092]\n",
      " [0.32142857 1.         0.50314096]\n",
      " [0.21428571 0.         0.4535572 ]\n",
      " [0.         1.         0.62991901]\n",
      " [0.14285714 1.         0.62977756]\n",
      " [0.         1.         0.62117442]\n",
      " [0.         1.         0.8115534 ]\n",
      " [0.03571429 1.         0.52828659]\n",
      " [0.35714286 1.         0.27966618]\n",
      " [0.07142857 1.         0.32680164]\n",
      " [0.46428571 0.         0.34295829]\n",
      " [0.03571429 1.         0.55328042]\n",
      " [0.14285714 1.         0.51585963]\n",
      " [0.10714286 1.         0.6152185 ]\n",
      " [0.46428571 1.         0.57535449]\n",
      " [0.14285714 1.         0.51882519]\n",
      " [0.57142857 0.75875486 0.29961804]\n",
      " [0.07142857 1.         0.91883116]\n",
      " [0.10714286 1.         0.59416125]\n",
      " [0.07142857 0.75875486 0.35756331]\n",
      " [0.17857143 1.         0.42494233]\n",
      " [0.07142857 1.         0.43924996]\n",
      " [0.17857143 0.75875486 0.5883026 ]\n",
      " [0.53571429 1.         0.27787156]\n",
      " [0.21428571 0.         0.14384216]\n",
      " [0.07142857 0.75875486 0.46457998]\n",
      " [0.17857143 1.         0.55117077]\n",
      " [0.28571429 1.         0.39271404]\n",
      " [0.32142857 1.         0.78595276]\n",
      " [0.96428571 0.         0.38735104]\n",
      " [0.07142857 1.         0.76164866]\n",
      " [0.         1.         0.37238031]\n",
      " [0.39285714 0.         0.54499328]\n",
      " [0.         1.         0.93860629]\n",
      " [0.21428571 1.         0.39144464]\n",
      " [0.07142857 1.         0.39901945]\n",
      " [0.28571429 1.         0.6659737 ]\n",
      " [0.03571429 1.         0.3934423 ]\n",
      " [0.07142857 0.         0.66452525]\n",
      " [0.10714286 0.75875486 0.4355405 ]\n",
      " [0.03571429 0.75875486 0.83187912]\n",
      " [0.35714286 1.         0.61253732]\n",
      " [0.07142857 1.         0.53358792]\n",
      " [0.07142857 0.         0.31103926]\n",
      " [0.67857143 1.         0.42129162]\n",
      " [0.03571429 1.         0.69838235]\n",
      " [0.17857143 1.         0.49350578]\n",
      " [0.         1.         0.93860629]\n",
      " [0.03571429 1.         0.62821526]\n",
      " [0.         0.75875486 0.54211328]\n",
      " [0.03571429 1.         0.42550319]\n",
      " [0.25       1.         0.42415221]\n",
      " [0.         1.         0.4781554 ]\n",
      " [0.07142857 1.         0.58232916]\n",
      " [0.         1.         0.62117442]\n",
      " [0.17857143 1.         0.55972724]\n",
      " [0.17857143 1.         0.40209554]\n",
      " [0.         1.         0.86109546]\n",
      " [0.         1.         0.39577389]\n",
      " [0.17857143 1.         0.4495562 ]\n",
      " [0.25       0.75875486 0.5691008 ]\n",
      " [0.28571429 0.         0.46851161]\n",
      " [0.03571429 1.         0.51745224]\n",
      " [0.46428571 1.         0.6368008 ]\n",
      " [0.35714286 0.         0.34662735]\n",
      " [0.32142857 1.         0.58905873]\n",
      " [0.46428571 1.         0.39969233]\n",
      " [0.03571429 1.         0.39466006]\n",
      " [0.10714286 1.         0.47892657]\n",
      " [0.07142857 0.         1.        ]\n",
      " [0.14285714 1.         0.7504492 ]\n",
      " [0.10714286 1.         0.53619506]\n",
      " [0.21428571 1.         0.78180621]\n",
      " [0.17857143 0.         0.29493351]\n",
      " [0.5        0.         0.29984353]\n",
      " [0.03571429 1.         0.36819276]\n",
      " [0.14285714 1.         0.17874955]\n",
      " [0.07142857 1.         0.14813616]\n",
      " [0.03571429 1.         0.78133257]\n",
      " [0.         0.75875486 0.38559645]\n",
      " [0.14285714 1.         0.73023859]\n",
      " [0.17857143 1.         0.533897  ]\n",
      " [0.28571429 1.         0.36434086]\n",
      " [1.         1.         0.4302689 ]\n",
      " [0.96428571 1.         0.33745345]\n",
      " [0.         1.         0.45386092]\n",
      " [0.07142857 1.         0.46848192]\n",
      " [0.25       1.         0.37443445]\n",
      " [0.03571429 0.75875486 0.78374399]\n",
      " [0.14285714 0.75875486 0.39081095]\n",
      " [0.39285714 1.         0.47546315]\n",
      " [0.03571429 1.         0.41803745]\n",
      " [0.17857143 1.         0.48253748]\n",
      " [0.39285714 1.         0.50143588]\n",
      " [0.35714286 1.         0.45500091]\n",
      " [0.10714286 1.         0.41450803]\n",
      " [0.03571429 1.         0.53071032]\n",
      " [0.10714286 0.75875486 0.5252734 ]\n",
      " [0.07142857 1.         0.70516791]\n",
      " [0.89285714 1.         0.45177168]\n",
      " [0.25       0.         0.10272452]\n",
      " [0.14285714 0.75875486 0.44680212]\n",
      " [0.14285714 1.         0.33021533]\n",
      " [0.10714286 1.         0.46785076]\n",
      " [0.25       0.75875486 0.41111627]\n",
      " [0.03571429 1.         0.82503435]\n",
      " [0.         1.         0.48493594]\n",
      " [0.14285714 0.         0.46525317]\n",
      " [0.03571429 1.         0.        ]\n",
      " [0.03571429 1.         0.78374399]\n",
      " [0.35714286 1.         0.39941669]\n",
      " [0.10714286 1.         0.26041672]\n",
      " [0.07142857 1.         0.44714787]\n",
      " [0.17857143 0.75875486 0.66271129]\n",
      " [0.         1.         0.471394  ]\n",
      " [0.21428571 0.75875486 0.33921736]\n",
      " [0.42857143 1.         0.55672748]\n",
      " [0.39285714 1.         0.52390999]\n",
      " [0.07142857 1.         0.46203219]\n",
      " [0.07142857 1.         0.53783222]\n",
      " [0.21428571 1.         0.27588001]\n",
      " [0.07142857 1.         0.42972798]\n",
      " [0.         1.         0.37985025]\n",
      " [0.07142857 1.         0.35456276]\n",
      " [0.03571429 1.         0.44512953]\n",
      " [0.         1.         0.43825095]\n",
      " [0.07142857 1.         0.36630965]\n",
      " [0.25       1.         0.48952501]\n",
      " [0.17857143 1.         0.49608505]\n",
      " [0.         1.         0.34790104]\n",
      " [0.35714286 1.         0.58595753]\n",
      " [0.14285714 0.         0.44572074]\n",
      " [0.         1.         0.39577389]\n",
      " [0.07142857 0.75875486 0.58232916]\n",
      " [0.         1.         0.46285339]\n",
      " [0.92857143 1.         0.27199917]\n",
      " [0.07142857 1.         0.27272556]\n",
      " [0.10714286 0.         0.36461651]\n",
      " [0.07142857 0.75875486 0.588512  ]\n",
      " [0.14285714 1.         0.18066214]\n",
      " [0.14285714 1.         0.56398891]\n",
      " [0.10714286 1.         0.46649895]\n",
      " [0.14285714 0.         0.33149502]\n",
      " [0.10714286 1.         0.44163483]\n",
      " [0.10714286 0.         0.32671936]\n",
      " [0.07142857 1.         0.39161739]\n",
      " [0.14285714 1.         0.53112535]\n",
      " [0.57142857 1.         0.43551955]\n",
      " [0.17857143 0.         0.30504729]\n",
      " [0.         1.         0.38559645]\n",
      " [0.07142857 1.         0.50342547]\n",
      " [0.03571429 1.         0.40431231]\n",
      " [0.14285714 1.         0.4492188 ]\n",
      " [0.07142857 1.         0.46166238]\n",
      " [0.10714286 1.         0.45373837]\n",
      " [0.28571429 1.         0.56801166]\n",
      " [0.32142857 1.         0.21266002]\n",
      " [0.         0.         0.21151239]\n",
      " [0.03571429 1.         0.50672943]\n",
      " [0.21428571 1.         0.62268698]]\n"
     ]
    }
   ],
   "source": [
    "print(norm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fcbc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAD8CAYAAAAoqlyCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZMElEQVR4nO3df5hU1Z3n8fe3u2EaFNJxDQVKj21sFyMy4kicGOaJgot2AAVEn6BD1tkH6SwTMyZPfojrKhkjaDYjE/dhosEfk81jopkYybqAbFyEYIhhREFEMQkaBBQK/NFBI4jd/d0/umA6hr5VZZ3q0/f6efnch66qe+75Hrv4cs4999xr7o6IiFSuJnYAIiJZoYQqIhKIEqqISCBKqCIigSihiogEooQqIhKIEqqISA/M7Etm9qyZbTaz+8ysPml/JVQRkSMws+OBvwfGuPtpQC0wI6mMEqqISM/qgAFmVgcMBF4ptnNVPb61LZNLsYY2JPb8pQ8Zpt9VatTXYZUeY8AZV5Wccw5s/OfPAa3d3lrs7osB3P1lM/tHYDuwH/iZu/8s6XhVT6giIr3KSh94F5Ln4iMexuzDwBTgRKAN+LGZzXT3e3s6nob8IpItZqVvyf4T8Dt33+vu7wIPAp9MKqAeqohkSxk91CK2A58ws4F0DfnPA9YnFVBCFZFsKd7zLIm7rzOzB4CngHZgAz2cHjhECVVEsqWmNtih3H0eMK/U/ZVQRSRbwg35y6aEKiLZEmjI/34ooYpItqiHKiISiHqoIiKBqIcqIhJIwFn+cimhiki2qIcqIhJIjc6hioiEoR6qiEggmuUXEQlEk1IiIoFoyF+Z1/bmufPWr7Ov7XUw49yWqZw/JfHRL33ewgU3sG7tGho+fAzfvffB2OEEk9V2rX1sDd+8ZT6dHZ1Mm34ps2a3Fi+UAqlsV8QhfyZuMF1bW8uMK69mwR0/4vpb72bl0gd4efuLscOqyISJU7hp4e2xwwgui+3q6Ohgwfwb+c4dd7HkoWWsWL6UF7ZujR1WxVLbLqspfQssEwm14ZhjaWo+BYABA4/iuMYm3nhtb+SoKjNq9JkMGjw4dhjBZbFdm5/ZRGPjCQxvbKRf//60TJzE6lUrY4dVsdS2K9wd+8tWdMhvZqfQ9VyV4wtvvQw85O5bgkcTwN78K7z04m84acTI2KHIB8SefJ6hw4Yefj0kl+OZTZsiRhRGatsV8RxqYs1mdg1wP2DAvxU2A+4zs7kJ5VrNbL2Zrf/p/d8LGG6yA/vfZtH8uVw++0sMGHh0r9UrIn1ITW3pW2DFeqizgJGFB1QdZmYLgWeBW45UqPuTBHvrMdLt7e0sWjCXs8e1MGbsuN6oUgTo6rnt3rX78Os9+Ty5XC5iRGGktl19tYcKdALHHeH9YYXP+gR3557bbmJYYxMt0y6PHY58wIw8bRTbt29j584dvHvwICuWL+OcceNjh1Wx1LYr0DlUMxthZhu7bfvM7ItJZYr1UL8IrDSz3wI7Cu/9OdAMXFVS43rBb597ml8++jDDm5q5/qqZAFxyxRxO//jYyJG9fzfPu4ZNG9azr62NmVMnMHPWHFouvDh2WBXLYrvq6uq49robmNN6JZ2dHUydNp3m5pNjh1Wx1LYrUA/V3X8NjAYws1q65o+WJFbtnjwiN7Ma4Cz+eFLqCXfvKCWo3hry97ahDfWxQ5ASDdPvKjXq66h46n3A1MUl55z9P20tqT4zOx+Y5+6JvbSis/zu3gn8qrTwREQiq8451BnAfcV2ysR1qCIih1hNTelbtyuSCtufLAUzs/7ARcCPi9WdiaWnIiKHWBkX7He/IinBp4Gn3D1f7HhKqCKSLeEXQF1GCcN9UEIVkYwpp4dawrGOAiYAnytlfyVUEcmUkAnV3f8A/IdS91dCFZFMqanR/VBFRMKIdztUJVQRyZaQQ/5yKaGKSKYooYqIBKKEKiISiBKqiEggVqOEKiIShHqoIiKBKKGKiISi61BFRMLIdA/1jKaGalchInJYphOqiEhv0lp+EZFQdA5VRCQMDflFRAJRQhURCUQJVUQkEC09FREJJGYPNd71BSIiVWBmJW8lHKvBzB4ws+fNbIuZnZ20v3qoIpIpgXuotwEr3P0SM+sPDEzaWQlVRLIlUD41sw8BnwL+FsDdDwIHk8poyC8imVLOkN/MWs1sfbettduhTgT2Av9iZhvM7C4zOyqpbiVUEcmUmhoreXP3xe4+ptu2uNuh6oC/BG539zOAPwBzE+uuYrtERHpdwEmpncBOd19XeP0AXQm2R0qoIpIpZqVvSdx9N7DDzEYU3joPeC6pjCalRCRTAs/yfwH4QWGG/0XgvyTtrIQqIpkSMp+6+0ZgTKn7Z2LIv/axNVw06QImt0zg7jsXFy+QEmpXemSxTZDOdpUzKRW87uBH7GUdHR0smH8j37njLpY8tIwVy5fywtatscOqmNqVHllsE6S3XUqoFdj8zCYaG09geGMj/fr3p2XiJFavWhk7rIqpXemRxTZBetsValLq/Uh9Qt2TzzN02NDDr4fkcuTz+YgRhaF2pUcW2wTpbVfItfzl0qSUiGRKKu82ZWY9Xj7QfTlXtU9kD8nl2L1r9+HXe/J5crlcVevsDWpXemSxTZDedqV1yP8PPX3QfTnXrNmtPe0WxMjTRrF9+zZ27tzBuwcPsmL5Ms4ZN76qdfYGtSs9stgmSG+7Yk5KJQ75zWxTTx8BfeKfqrq6Oq697gbmtF5JZ2cHU6dNp7n55NhhVUztSo8stgnS266YQ35z954/NMsDFwBvvPcj4JfuflyxCg6003MFIiLd1NdVfvO9MTetKjnnrP/v44Jm32KTUkuBowurBf6Ima0OGYiISAh99iF97j4r4bPLw4cjIlKZiPlUl02JSLb02R6qiEjaVGP2vlRKqCKSKRryi4gEoiG/iEgg6qGKiASiHqqISCBKqCIigYSc5TezbcCbQAfQ7u6Jj0NRQhWRTKlCB3Wcu79ayo5KqCKSKam8H6qISF9Uzv1Qu9+7ubC9936jDvzMzJ48wmd/Qj1UEcmUmjJ6qO6+GEi6C/5fu/vLZjYEeMTMnnf3NT3WXXqYIiJ9X8gbTLv7y4U/9wBLgLMS6w7SAhGRPqLGSt+SmNlRZjbo0M/A+cDmpDIa8otIpgSclMoBSwrHqwN+6O4rkgpUPaHuajtQ7SqiGNZQHzuE4D721WWxQ6iKH35+bOwQgjujqSF2CH1WqHzq7i8Cp5dTRj1UEckUq/wpKu+bEqqIZErE26EqoYpItugG0yIigZRzHWpoSqgikim6H6qISCC6fZ+ISCDqoYqIBFKrHqqISBga8ouIBKLrUEVEAlEPVUQkEE1KiYgEoh6qiEggtVp6KiISRsQRvxKqiGSL1vKLiASiSakKLVxwA+vWrqHhw8fw3XsfjB1OMGsfW8M3b5lPZ0cn06ZfyqzZRZ9imwqD6uv45oy/4D8OHYQDX7vvaTa81BY7rPfttb157rz16+xrex3MOLdlKudPmRE7rCDS+B3UpFSFJkycwoXTL+Mfv3Fd7FCC6ejoYMH8G/nunf9CLpfj8s9cwrnjxnNSc3Ps0Co27+KR/HzLXv7ue0/Rr9ao71cbO6SK1NbWMuPKq2lqPoX9b/+Br199BSPPOIvj//yjsUOrSFq/g6HzqZnVAuuBl919ctK+mXjq6ajRZzJo8ODYYQS1+ZlNNDaewPDGRvr170/LxEmsXrUydlgVG1Rfx1kfPYYfrdsBwLsdzpsH2iNHVZmGY46lqfkUAAYMPIrjGpt447W9kaOqXFq/g7U1VvJWoquBLaXsWDShmtkpZnaemR39nvdbSo1Gyrcnn2fosKGHXw/J5cjn8xEjCmP4MQN5/a2DfOuyv2Dpl/+aWz4zigH9091D7W5v/hVeevE3nDRiZOxQKpbW76CZlbyVcKzhwCTgrlLqTkyoZvb3wP8GvgBsNrMp3T5ekFCu1czWm9n6+75/dylxyAdEXa0xcvhgfrB2O5Nv/QVvH+xgznknxQ4riAP732bR/LlcPvtLDBh4dPECUhU1ZWzdc1Vhe+9J4m8DXwM6S6m72DnU2cCZ7v6WmTUBD5hZk7vfRsLlXu6+GFgM8LtXD3gpgcgfG5LLsXvX7sOv9+Tz5HK5iBGFsavtALt/f4CN29sAePjpXfzX8/r2OblStLe3s2jBXM4e18KYseNihxNEWr+D5UxKdc9VRzjOZGCPuz9pZueWcrxiQ/4ad3+rUPE24Fzg02a2kLjXz2beyNNGsX37Nnbu3MG7Bw+yYvkyzhk3PnZYFXv1zXfY1XaAj37kKAA+efKxbN39ZuSoKuPu3HPbTQxrbKJl2uWxwwkmrd/BGit9K2IscJGZbQPuB8ab2b1JBYr1UPNmNtrdNwIUeqqTgXuAUSW0rVfcPO8aNm1Yz762NmZOncDMWXNoufDi2GFVpK6ujmuvu4E5rVfS2dnB1GnTaW4+OXZYQcz7ybP802dH07+2hu2vvc1X73s6dkgV+e1zT/PLRx9meFMz1181E4BLrpjD6R8fGzmyyqT1Oxhq6am7XwtcC1DooX7F3WcmlTH3nkfkhROy7e6++wifjXX3tcWCyuqQf1hDfewQgvvYV5fFDqEqfvj5dCe2IzmjqSF2CFVRX1f5yPerS39dcs751uQRJdXXLaEmXjaV2EN1950JnxVNpiIiva0a1/W7+2pgdbH9MnFhv4jIIVrLLyISSMzVSkqoIpIpujmKiEggusG0iEggeuqpiEggmpQSEQlE51BFRALRkF9EJBCLeJsRJVQRyZS6iBeiKqGKSKbomVIiIoHoHKqISCCa5RcRCUTXoYqIBFKrSSkRkTBqsnzZVBbvbJ9VW741KXYIUqJdbQdih1AVJx5beb7QOVQRkUA0yy8iEkioSSkzqwfWAH9GV658wN3nJZVRQhWRTAk45H8HGF942nM/4Bdm9rC7/6qnAkqoIpIpAR8j7cBbhZf9ClviE1VjPn5FRCS4mjI2M2s1s/XdttbuxzKzWjPbCOwBHnH3dUl1q4cqIplSzlp+d18MLE74vAMYbWYNwBIzO83dN/e0v3qoIpIpVsZWKndvA1YBLUn7KaGKSKbUmJW8JTGzjxR6ppjZAGAC8HxSGQ35RSRTAl6GOgz4X2ZWS1fn81/dfWlSASVUEcmUmnCz/JuAM8opo4QqIpkS8zymEqqIZIru2C8iEkjEpfxKqCKSLeqhiogEUquEKiISRswhfyYu7F/72BoumnQBk1smcPedPa4iSx21Kz2y2KaFC27gM5PO5XMzL44dSlnMSt9CS31C7ejoYMH8G/nOHXex5KFlrFi+lBe2bo0dVsXUrvTIYpsAJkycwk0Lb48dRtlqsJK38HWn3OZnNtHYeALDGxvp178/LRMnsXrVythhVUztSo8stglg1OgzGTR4cOwwyqYeagX25PMMHTb08OshuRz5fD5iRGGoXemRxTalmZXxX2hFJ6XM7Cy67rX6hJmdStfdVp539+XBoxERqVDMWf7EHqqZzQP+J3C7md0MLAKOAuaa2XUJ5Q7ftLXaJ+iH5HLs3rX78Os9+Ty5XK6qdfYGtSs9stimNOvLQ/5LgLHAp4DPA1Pd/RvABcBneirk7ovdfYy7j5k1u7Wn3YIYedootm/fxs6dO3j34EFWLF/GOePGV7XO3qB2pUcW25RmMRNqsSF/e+GO1W+b2Qvuvg/A3febWWf4cMpXV1fHtdfdwJzWK+ns7GDqtOk0N58cO6yKqV3pkcU2Adw87xo2bVjPvrY2Zk6dwMxZc2i5sO9fQlWNc6Ml1931HKoePjRbB4xz97fNrMbdOwvvfwhY5e5/WayCA+3JD7USkfLtajsQO4SqOPHY+oqz4crnXy0555x3yrFBs2+xHuqn3P0dgEPJtKAfcEXIQEREQih2J/5qSkyoh5LpEd5/FXi1KhGJiFQg5pBfa/lFJFMC3bD//dUdr2oRkfBCXdhvZo1mtsrMnjOzZ83s6mJ1q4cqIpkS8BRqO/Bld3/KzAYBT5rZI+7+XE8F1EMVkUyxMrYk7r7L3Z8q/PwmsAU4PqmMeqgikinlLD01s1ag++qjxe7+J8s7zayJriegrks6nhKqiGRLGUP+QvJMXB9vZkcDPwG+eGhxU0+UUEUkU0JeNmVm/ehKpj9w9weL7a+EKiKZEmpSyrqe9nc3sMXdF5ZSRpNSIpIpoSal6Lox1GeB8Wa2sbBNTCqgHqqIZEugHqq7/6Lcoymhikim9Nm1/CIiaRPzMdJKqCKSLREzqhKqiGSK7jYlIhJIxFOoSqjy7zZsa4sdQlUMbaiPHUJwp074SuwQqmL/hkUVH0MJVUQkEA35RUQCUQ9VRCQQXTYlIhKKeqgiImHoHKqISCAxH9KnhCoi2aKEKiIShob8IiKB6LIpEZFAdNmUiEgo6qGKiIQR8wbTeqaUiGRKwGdKYWb3mNkeM9tcSt1KqCKSLSEzKnwPaCm1ag35RSRTQl425e5rzKyp1P2VUEUkU2JeNqUhv4hkilk5m7Wa2fpuW2sldWeih7r2sTV885b5dHZ0Mm36pcyaXdH/kz4ji+16bW+eO2/9OvvaXgczzm2ZyvlTZsQOq2ILF9zAurVraPjwMXz33gdjhxPMF/5mHH877ZO4O89ufYXWeffyzsH22GElKmfI7+6LgcWh6k59D7Wjo4MF82/kO3fcxZKHlrFi+VJe2Lo1dlgVy2q7amtrmXHl1Sy440dcf+vdrFz6AC9vfzF2WBWbMHEKNy28PXYYQR33kQ/xd5edw9i/+R+MuXQBtTU1XHrBmbHDKqqcHmpoqU+om5/ZRGPjCQxvbKRf//60TJzE6lUrY4dVsay2q+GYY2lqPgWAAQOP4rjGJt54bW/kqCo3avSZDBo8OHYYwdXV1jLgz/pRW1vDgPr+7Nr7+9ghFRX4sqn7gMeBEWa208xmJe1f9pDfzL7v7v+53HLVsiefZ+iwoYdfD8nleGbTpogRhZHVdnW3N/8KL734G04aMTJ2KHIEr+z9Pd/+/kp+8/A32P/OQVY+/jwrf/V87LCKCtnzdPfLytk/sYdqZg+9Z/s/wMWHXieUO3yi9+47g52ekAw5sP9tFs2fy+Wzv8SAgUfHDkeOoGHQACafO4qPTZ7HR8+/jqMG9GfGxI/HDqsEYS9ELUexHupw4DngLsALEYwBbk0q1P1E74F2vPIwezYkl2P3rt2HX+/J58nlctWssldktV0A7e3tLFowl7PHtTBm7LjY4UgPxv/VKWx75TVefeMtAH766NN84vQTuX/5E5EjSxbzBtPFzqGOAZ4ErgN+7+6rgf3u/nN3/3m1gyvFyNNGsX37Nnbu3MG7Bw+yYvkyzhk3PnZYFctqu9yde267iWGNTbRMuzx2OJJgx+7XOWvUiQyo7wfAuLNG8Ovf5SNHVVzMSanEHqq7dwL/ZGY/LvyZL1amt9XV1XHtdTcwp/VKOjs7mDptOs3NJ8cOq2JZbddvn3uaXz76MMObmrn+qpkAXHLFHE7/+NjIkVXm5nnXsGnDeva1tTFz6gRmzppDy4UXxw6rIk9sfokl/28Dj//wGto7Onn6+Z3c/ZO1scMqKuYNps299BG5mU0Cxrr7fyu1TLWH/BLOhm1tsUOoiqEN9bFDCO7UCV+JHUJV7N+wqOJsuHvfuyXnnKGD+wXNvmX1Nt19GbAsZAAiIiHpBtMiIoHoESgiIoFYxIyqhCoimaIhv4hIIBryi4gEEvOyKSVUEckU9VBFRAJRQhURCURDfhGRQNRDFREJRJdNiYiEoh6qiEgYOocqIhJIX77BtIhIugR8AoqZtZjZr81sq5nNLba/EqqIZIqV8V/iccxqgX8GPg2cClxmZqcmlVFCFZFMCfgIlLOAre7+orsfBO4HpiQVqPo51Pq63jtDbGathQcEZkpvtevs5oZqV3GYfleV2b9hUbWrOCxtv6tyco6ZtQKt3d5a3K2txwM7un22E/irpONlrYfaWnyXVMpiu7LYJshmu7LYJqDrCc3uPqbbVtE/HFlLqCIiobwMNHZ7PbzwXo+UUEVEjuwJ4GQzO9HM+gMzgIeSCmTtOtTUnOcpUxbblcU2QTbblcU2FeXu7WZ2FfB/gVrgHnd/NqlMWY+RFhGRnmnILyISiBKqiEggmUio5S4PSwMzu8fM9pjZ5tixhGRmjWa2ysyeM7Nnzezq2DFVyszqzezfzOzpQpv+IXZMIZlZrZltMLOlsWPp61KfUN/P8rCU+B7QEjuIKmgHvuzupwKfAD6fgd/XO8B4dz8dGA20mNkn4oYU1NXAlthBpEHqEyrvY3lYGrj7GuD12HGE5u673P2pws9v0vUX9fi4UVXGu7xVeNmvsGVittfMhgOTgLtix5IGWUioR1oeluq/oB8UZtYEnAGsixxKxQrD4o3AHuARd099mwq+DXwN6IwcRypkIaFKCpnZ0cBPgC+6+77Y8VTK3TvcfTRdq2nOMrPTIodUMTObDOxx9ydjx5IWWUioZS8Pk7jMrB9dyfQH7v5g7HhCcvc2YBXZOP89FrjIzLbRdSptvJndGzekvi0LCbXs5WESj5kZcDewxd0Xxo4nBDP7iJk1FH4eAEwAno8aVADufq27D3f3Jrr+Xj3q7jMjh9WnpT6huns7cGh52BbgX4stD0sDM7sPeBwYYWY7zWxW7JgCGQt8lq7ezsbCNjF2UBUaBqwys010/QP/iLvrEqMPIC09FREJJPU9VBGRvkIJVUQkECVUEZFAlFBFRAJRQhURCUQJVUQkECVUEZFA/j/C/7ldmodnsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.aux_functions import confusion_matrix\n",
    "from src.aux_functions import plot_matrix\n",
    "from src.aux_functions import plot_precision\n",
    "from seaborn import heatmap\n",
    "\n",
    "for i in range(crossed_validation):\n",
    "    # separo por lotes al conjunto de entrenamiento/testeo para la validacion cruzada\n",
    "    test_batch = np.array(range(batch_size * i, batch_size * (i + 1), 1))\n",
    "\n",
    "    # b) Dividir el conjunto de datos en un conjunto de entrenamiento y otro de prueba.\n",
    "    X = np.delete(norm_data, test_batch, axis = 0)\n",
    "    f_X = np.delete(register_class, test_batch, axis = 0)\n",
    "    Y = norm_data[test_batch[0]:(test_batch[-1] + 1)]\n",
    "    f_Y = register_class[test_batch[0]:(test_batch[-1] + 1)]\n",
    "\n",
    "    knn = KNN(X, f_X, classes)\n",
    "    weight_knn = WeightedKNN(X, f_X, classes)\n",
    "\n",
    "    predictions = knn.batch_classify(Y)\n",
    "    weight_predictions = weight_knn.batch_classify(Y)\n",
    "    \n",
    "    knn_confusion = confusion_matrix(predictions, f_Y, classes)\n",
    "    weight_knn_confusion = confusion_matrix(weight_predictions, f_Y, classes)\n",
    "\n",
    "    knn_precisions[i] = knn_confusion.trace()/knn_confusion.sum()\n",
    "    weight_knn_precisions[i] = weight_knn_confusion.trace()/weight_knn_confusion.sum()\n",
    "    plot_matrix(knn_confusion, f'crossed_validation_{crossed_validation}_{i}.png')\n",
    "    if i == 2:\n",
    "        heatmap(knn_confusion, annot=True, cmap='Blues', fmt='g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f9f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision(knn_precisions, weight_knn_precisions, crossed_validation, filename=f'precision_{crossed_validation}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5024ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from seaborn import heatmap\n",
    "heatmap(knn_precisions, annot=True, cmap='Blues', fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.aux_functions import plot_precision_k\n",
    "\n",
    "knn_means = []\n",
    "\n",
    "weight_knn_means = []\n",
    "\n",
    "# neighbours = np.arange(start=3, stop=20, step=2)\n",
    "# for k in neighbours:\n",
    "\n",
    "# iterations = np.arange(start=1, stop=15, step=1)\n",
    "# for index in iterations:\n",
    "#     validation_range = neighbours = np.arange(start=3, stop=20, step=1)\n",
    "#     knn_precisions_avg = np.zeros(len(validation_range))\n",
    "#     weight_knn_precisions_avg = np.zeros(len(validation_range))\n",
    "\n",
    "validation_range = neighbours = np.arange(start=3, stop=25, step=1)\n",
    "for crossed_validation in validation_range:        \n",
    "\n",
    "    iterations = np.arange(start=0, stop=15, step=1)\n",
    "    knn_precisions_avg = np.zeros(len(iterations))\n",
    "    weight_knn_precisions_avg = np.zeros(len(iterations))\n",
    "    for index in iterations:\n",
    "\n",
    "        reviews_sentiment = reviews_sentiment.sample(frac=1).reset_index(drop=True)\n",
    "        register_class = np.array(reviews_sentiment.starRating)\n",
    "        classes = np.array(reviews_sentiment.starRating.unique())\n",
    "        # Se normalizan los datos por cada columna\n",
    "        norm_data = np.array(normalize_df(reviews_sentiment[attributes])) # me queda un arreglo de registros con 3 atributos\n",
    "        batch_size = math.floor(len(norm_data)/crossed_validation)\n",
    "\n",
    "        # valores de precision para cada corrido de validacion cruzada\n",
    "        knn_precisions = np.zeros(crossed_validation)\n",
    "        weight_knn_precisions = np.zeros(crossed_validation)\n",
    "\n",
    "        for i in range(crossed_validation):\n",
    "            # separo por lotes al conjunto de entrenamiento/testeo para la validacion cruzada\n",
    "            test_batch = np.array(range(batch_size * i, batch_size * (i + 1), 1))\n",
    "\n",
    "            # b) Dividir el conjunto de datos en un conjunto de entrenamiento y otro de prueba.\n",
    "            X = np.delete(norm_data, test_batch, axis = 0)\n",
    "            f_X = np.delete(register_class, test_batch, axis = 0)\n",
    "            Y = norm_data[test_batch[0]:(test_batch[-1] + 1)]\n",
    "            f_Y = register_class[test_batch[0]:(test_batch[-1] + 1)]\n",
    "\n",
    "            knn = KNN(X, f_X, classes)\n",
    "            weight_knn = WeightedKNN(X, f_X, classes)\n",
    "\n",
    "            predictions = knn.batch_classify(Y)\n",
    "            weight_predictions = weight_knn.batch_classify(Y)\n",
    "\n",
    "            knn_confusion = confusion_matrix(predictions, f_Y, classes)\n",
    "            weight_knn_confusion = confusion_matrix(weight_predictions, f_Y, classes)\n",
    "\n",
    "            knn_precisions[i] = knn_confusion.trace()/knn_confusion.sum()\n",
    "            weight_knn_precisions[i] = weight_knn_confusion.trace()/weight_knn_confusion.sum()\n",
    "        #     plot_matrix(weight_knn_confusion, f'crossed_validation_{crossed_validation}_{i}.png')\n",
    "\n",
    "\n",
    "        knn_precisions_avg[index] = knn_precisions.mean()\n",
    "        weight_knn_precisions_avg[index] = weight_knn_precisions.mean()\n",
    "\n",
    "#     print(knn_precisions_avg.mean())\n",
    "    knn_means.append(knn_precisions_avg.mean())\n",
    "    #knn_stds.append(knn_precisions_avg.std())\n",
    "    weight_knn_means.append(weight_knn_precisions_avg.mean())\n",
    "    #w_knn_stds.append(weight_knn_precisions_avg.std())\n",
    "print('knn[6]: ' + str(knn_means[6]))\n",
    "print('knn_w[6]: ' + str(weight_knn_means[6]))\n",
    "plot_precision_k(knn_means, weight_knn_means, validation_range, f'crossed_validation_knn_means.png')\n",
    "#     print(f'Finished neighbour {neigh_k}.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_k(knn_means, weight_knn_means, validation_range, f'crossed_validation_knn_means.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba33420",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('knn[6]: ' + str(knn_means[12]))\n",
    "print('knn_w[6]: ' + str(weight_knn_means[10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
